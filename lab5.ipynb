{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install scikit-learn pandas matplotlib seaborn imblearn joblib shap --quiet\n",
        "\n",
        "# Create a dummy dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'Attr1': np.random.rand(1000) * 10,\n",
        "    'Attr2': np.random.rand(1000) * 100,\n",
        "    'Attr3': np.random.rand(1000) * 50,\n",
        "    'Attr4': np.random.rand(1000) * 200,\n",
        "    'Attr5': np.random.rand(1000) * 30,\n",
        "    'Attr6': np.random.rand(1000) * 15,\n",
        "    'Bankrupt?': np.random.choice([0, 1], size=1000, p=[0.95, 0.05])\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.loc[df.sample(frac=0.05).index, 'Attr2'] = np.nan\n",
        "df['Attr_Corr'] = df['Attr1'] * 1.5 + np.random.normal(0, 0.1, 1000)\n",
        "\n",
        "df.to_csv('data.csv', index=False)\n",
        "print(\"Dummy data.csv created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mte1PZwIJQvz",
        "outputId": "40879266-4c8a-4fc2-94c9-9ab99cb9562d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy data.csv created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from typing import Tuple, Dict, Any, List\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, f1_score, precision_score, recall_score,\n",
        "    brier_score_loss, roc_curve, precision_recall_curve\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "except ImportError:\n",
        "    shap = None\n",
        "    print(\"SHAP library not found. Install with 'pip install shap' to enable interpretability plots.\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Utility: ensure output dirs\n",
        "# ----------------------------\n",
        "def ensure_dir(path: str) -> str:\n",
        "    \"\"\"Ensures a directory exists, creating it if necessary.\"\"\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "\n",
        "def safe_name(s: str) -> str:\n",
        "    \"\"\"Converts a string to a safe filename.\"\"\"\n",
        "    return \"\".join(ch if ch.isalnum() or ch in \" _\" else \"_\" for ch in s).replace(\" \", \"_\")[:100]\n",
        "\n",
        "\n",
        "def short_name(s: str, maxlen: int = 16) -> str:\n",
        "    \"\"\"Truncates a string for use in plots.\"\"\"\n",
        "    s2 = s.strip()\n",
        "    return (s2[:maxlen - 1] + \"â€¦\") if len(s2) > maxlen else s2\n",
        "\n",
        "\n",
        "# ---------------------------------\n",
        "# EDA: hist, box, correlation heat\n",
        "# ---------------------------------\n",
        "def eda_plots(X: pd.DataFrame, y: pd.Series, out_dir: str, max_hist: int = 24) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates and saves exploratory data analysis plots.\n",
        "    \"\"\"\n",
        "    eda_dir = ensure_dir(os.path.join(out_dir, \"eda\"))\n",
        "\n",
        "    X.describe().to_csv(os.path.join(eda_dir, \"feature_describe.csv\"))\n",
        "    X.isna().sum().sort_values(ascending=False).to_csv(os.path.join(eda_dir, \"missing_values.csv\"))\n",
        "\n",
        "    cols = X.columns[:max_hist]\n",
        "    for c in cols:\n",
        "        fig = plt.figure(figsize=(6, 4))\n",
        "        plt.hist(X[c].dropna().values, bins=50)\n",
        "        plt.title(f\"Histogram: {c}\")\n",
        "        plt.xlabel(c)\n",
        "        plt.ylabel(\"Count\")\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(os.path.join(eda_dir, f\"hist_{safe_name(c)}.png\"))\n",
        "        plt.close(fig)\n",
        "\n",
        "    for c in cols:\n",
        "        fig = plt.figure(figsize=(6, 4))\n",
        "        plt.boxplot(X[c].dropna().values, vert=True)\n",
        "        plt.title(f\"Boxplot: {c}\")\n",
        "        plt.ylabel(c)\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(os.path.join(eda_dir, f\"box_{safe_name(c)}.png\"))\n",
        "        plt.close(fig)\n",
        "\n",
        "    corr = X[cols].corr().values\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(X[cols].corr(), cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title(\"Correlation heatmap (subset)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(eda_dir, \"correlation_heatmap_subset.png\"))\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = plt.figure(figsize=(5, 4))\n",
        "    counts = y.value_counts().sort_index()\n",
        "    plt.bar(counts.index.astype(str), counts.values)\n",
        "    plt.title(\"Class balance (0=non-bankrupt, 1=bankrupt)\")\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(eda_dir, \"class_balance.png\"))\n",
        "    plt.close(fig)\n",
        "\n",
        "    return {\n",
        "        \"describe_csv\": \"eda/feature_describe.csv\",\n",
        "        \"missing_csv\": \"eda/missing_values.csv\",\n",
        "        \"histograms\": [f\"eda/hist_{safe_name(c)}.png\" for c in cols],\n",
        "        \"boxplots\": [f\"eda/box_{safe_name(c)}.png\" for c in cols],\n",
        "        \"corr_heatmap\": \"eda/correlation_heatmap_subset.png\",\n",
        "        \"class_balance\": \"eda/class_balance.png\"\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# Feature selection: simple corr filtering\n",
        "# -----------------------------------------\n",
        "def correlation_filter(X: pd.DataFrame, y: pd.Series, threshold: float = 0.95) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Removes one feature from highly correlated pairs based on target correlation.\n",
        "    \"\"\"\n",
        "    target_corr = X.apply(lambda col: pd.Series(col).corr(y), axis=0).abs().fillna(0.0)\n",
        "\n",
        "    corr = X.corr().abs()\n",
        "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "    to_drop = set()\n",
        "\n",
        "    for col in upper.columns:\n",
        "        high = [row for row in upper.index if (upper.loc[row, col] > threshold)]\n",
        "        for row in high:\n",
        "            if row in to_drop or col in to_drop:\n",
        "                continue\n",
        "            keep = col if target_corr[col] >= target_corr[row] else row\n",
        "            drop = row if keep == col else col\n",
        "            to_drop.add(drop)\n",
        "\n",
        "    selected_cols = [c for c in X.columns if c not in to_drop]\n",
        "    return selected_cols, sorted(list(to_drop))\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PSI (train vs. test)\n",
        "# -------------------------\n",
        "def calculate_psi(expected: np.ndarray, actual: np.ndarray, buckets: int = 10) -> float:\n",
        "    \"\"\"Calculates Population Stability Index over fixed quantile buckets.\"\"\"\n",
        "    expected = np.array(expected).astype(float)\n",
        "    actual = np.array(actual).astype(float)\n",
        "\n",
        "    quantiles = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
        "    quantiles[0] = -np.inf\n",
        "    quantiles[-1] = np.inf\n",
        "\n",
        "    expected_bins = np.digitize(expected, quantiles[1:-1])\n",
        "    actual_bins = np.digitize(actual, quantiles[1:-1])\n",
        "\n",
        "    exp_counts = np.bincount(expected_bins, minlength=buckets) / len(expected)\n",
        "    act_counts = np.bincount(actual_bins, minlength=buckets) / len(actual)\n",
        "\n",
        "    exp_counts = np.where(exp_counts == 0, 1e-6, exp_counts)\n",
        "    act_counts = np.where(act_counts == 0, 1e-6, act_counts)\n",
        "\n",
        "    psi_vals = (exp_counts - act_counts) * np.log(exp_counts / act_counts)\n",
        "    return float(np.sum(psi_vals))\n",
        "\n",
        "\n",
        "def psi_report(X_train: pd.DataFrame, X_test: pd.DataFrame, out_dir: str, topn: int = 10) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculates and reports PSI scores, including visualizations for top drifting features.\n",
        "    \"\"\"\n",
        "    psi_dir = ensure_dir(os.path.join(out_dir, \"psi\"))\n",
        "    psi_scores = []\n",
        "    for col in X_train.columns:\n",
        "        try:\n",
        "            psi = calculate_psi(X_train[col].values, X_test[col].values, buckets=10)\n",
        "            psi_scores.append((col, psi))\n",
        "        except Exception:\n",
        "            continue\n",
        "    psi_df = pd.DataFrame(psi_scores, columns=[\"feature\", \"psi\"]).sort_values(\"psi\", ascending=False)\n",
        "    psi_df.to_csv(os.path.join(psi_dir, \"psi_scores.csv\"), index=False)\n",
        "\n",
        "    top = psi_df.head(topn)\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    plt.barh([short_name(c, 30) for c in top[\"feature\"][::-1]], top[\"psi\"][::-1].values)\n",
        "    plt.xlabel(\"PSI\")\n",
        "    plt.title(f\"Top {topn} PSI features (train vs. test)\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(psi_dir, \"psi_topn.png\"))\n",
        "    plt.close(fig)\n",
        "\n",
        "    for feat in top[\"feature\"].head(3):\n",
        "        fig = plt.figure(figsize=(8, 4))\n",
        "        plt.hist(X_train[feat].dropna().values, bins=50, alpha=0.5, label=\"train\")\n",
        "        plt.hist(X_test[feat].dropna().values, bins=50, alpha=0.5, label=\"test\")\n",
        "        plt.title(f\"Train vs Test distribution: {feat}\")\n",
        "        plt.legend()\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(os.path.join(psi_dir, f\"dist_train_vs_test_{safe_name(feat)}.png\"))\n",
        "        plt.close(fig)\n",
        "\n",
        "    return {\n",
        "        \"psi_csv\": \"psi/psi_scores.csv\",\n",
        "        \"psi_topn_png\": \"psi/psi_topn.png\",\n",
        "        \"psi_overlay_pngs\": [f\"psi/dist_train_vs_test_{safe_name(f)}.png\" for f in top[\"feature\"].head(3)]\n",
        "    }\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Model defs & tuning\n",
        "# -------------------------\n",
        "def get_models_and_spaces(random_state: int = 42):\n",
        "    \"\"\"Defines models and their hyperparameter search spaces.\"\"\"\n",
        "    lr = LogisticRegression(class_weight=\"balanced\", max_iter=2000, random_state=random_state, solver=\"liblinear\")\n",
        "    rf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=300, random_state=random_state, n_jobs=-1)\n",
        "    nb = GaussianNB()\n",
        "\n",
        "    lr_grid = {\"C\": [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
        "    rf_space = {\n",
        "        \"n_estimators\": [200, 400, 600],\n",
        "        \"max_depth\": [None, 8, 16, 24, 32],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"max_features\": [\"sqrt\", \"log2\", 0.4, 0.6]\n",
        "    }\n",
        "    nb_grid = {\"var_smoothing\": np.logspace(-12, -6, 7)}\n",
        "\n",
        "    return ((\"Logistic Regression\", lr, lr_grid),\n",
        "            (\"Random Forest\", rf, rf_space),\n",
        "            (\"GaussianNB\", nb, nb_grid))\n",
        "\n",
        "\n",
        "def tune_model(name: str, model: Any, space: Dict, X: pd.DataFrame, y: pd.Series, scoring: str = \"roc_auc\", random_state: int = 42):\n",
        "    \"\"\"Tunes hyperparameters for a given model.\"\"\"\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "    if name == \"Random Forest\":\n",
        "        search = RandomizedSearchCV(model, space, n_iter=20, scoring=scoring, cv=cv, n_jobs=-1, random_state=random_state, verbose=0)\n",
        "    else:\n",
        "        search = GridSearchCV(model, space, scoring=scoring, cv=cv, n_jobs=-1, verbose=0)\n",
        "    search.fit(X, y)\n",
        "    return search.best_estimator_, search.best_params_, search.best_score_\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation & plots\n",
        "# -------------------------\n",
        "def evaluate_model(model: Any, X_tr: pd.DataFrame, y_tr: pd.Series, X_te: pd.DataFrame, y_te: pd.Series, label: str, out_dir: str):\n",
        "    \"\"\"Evaluates a model and generates performance plots.\"\"\"\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        p_tr = model.predict_proba(X_tr)[:, 1]\n",
        "        p_te = model.predict_proba(X_te)[:, 1]\n",
        "    else:\n",
        "        p_tr = model.decision_function(X_tr)\n",
        "        p_te = model.decision_function(X_te)\n",
        "\n",
        "    yhat_tr = (p_tr >= 0.5).astype(int)\n",
        "    yhat_te = (p_te >= 0.5).astype(int)\n",
        "\n",
        "    metrics = {\n",
        "        \"roc_auc_train\": roc_auc_score(y_tr, p_tr),\n",
        "        \"roc_auc_test\": roc_auc_score(y_te, p_te),\n",
        "        \"pr_auc_train\": average_precision_score(y_tr, p_tr),\n",
        "        \"pr_auc_test\": average_precision_score(y_te, p_te),\n",
        "        \"brier_train\": brier_score_loss(y_tr, p_tr),\n",
        "        \"brier_test\": brier_score_loss(y_te, p_te),\n",
        "        \"f1_train\": f1_score(y_tr, yhat_tr, zero_division=0),\n",
        "        \"f1_test\": f1_score(y_te, yhat_te, zero_division=0),\n",
        "        \"precision_train\": precision_score(y_tr, yhat_tr, zero_division=0),\n",
        "        \"precision_test\": precision_score(y_te, yhat_te, zero_division=0),\n",
        "        \"recall_train\": recall_score(y_tr, yhat_tr, zero_division=0),\n",
        "        \"recall_test\": recall_score(y_te, yhat_te, zero_division=0),\n",
        "    }\n",
        "\n",
        "    plots_dir = ensure_dir(os.path.join(out_dir, \"plots\", safe_name(label)))\n",
        "\n",
        "    fpr_tr, tpr_tr, _ = roc_curve(y_tr, p_tr)\n",
        "    fpr_te, tpr_te, _ = roc_curve(y_te, p_te)\n",
        "    fig = plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr_tr, tpr_tr, label=f\"Train (AUC={metrics['roc_auc_train']:.3f})\")\n",
        "    plt.plot(fpr_te, tpr_te, label=f\"Test (AUC={metrics['roc_auc_test']:.3f})\")\n",
        "    plt.plot([0, 1], [0, 1], \"k--\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC â€” {label}\")\n",
        "    plt.legend()\n",
        "    fig.tight_layout()\n",
        "    roc_path = os.path.join(plots_dir, \"roc.png\")\n",
        "    fig.savefig(roc_path)\n",
        "    plt.close(fig)\n",
        "\n",
        "    pr_tr, rc_tr, _ = precision_recall_curve(y_tr, p_tr)\n",
        "    pr_te, rc_te, _ = precision_recall_curve(y_te, p_te)\n",
        "    fig = plt.figure(figsize=(6, 5))\n",
        "    plt.plot(rc_tr, pr_tr, label=f\"Train (AP={metrics['pr_auc_train']:.3f})\")\n",
        "    plt.plot(rc_te, pr_te, label=f\"Test (AP={metrics['pr_auc_test']:.3f})\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"Precision-Recall â€” {label}\")\n",
        "    plt.legend()\n",
        "    fig.tight_layout()\n",
        "    pr_path = os.path.join(plots_dir, \"pr.png\")\n",
        "    fig.savefig(pr_path)\n",
        "    plt.close(fig)\n",
        "\n",
        "    frac_pos_tr, mean_pred_tr = calibration_curve(y_tr, p_tr, n_bins=10, strategy=\"quantile\")\n",
        "    frac_pos_te, mean_pred_te = calibration_curve(y_te, p_te, n_bins=10, strategy=\"quantile\")\n",
        "    fig = plt.figure(figsize=(6, 5))\n",
        "    plt.plot([0, 1], [0, 1], \"k--\")\n",
        "    plt.plot(mean_pred_tr, frac_pos_tr, marker=\"o\", label=f\"Train (Brier={metrics['brier_train']:.3f})\")\n",
        "    plt.plot(mean_pred_te, frac_pos_te, marker=\"o\", label=f\"Test (Brier={metrics['brier_test']:.3f})\")\n",
        "    plt.xlabel(\"Mean predicted probability\")\n",
        "    plt.ylabel(\"Fraction of positives\")\n",
        "    plt.title(f\"Calibration â€” {label}\")\n",
        "    plt.legend()\n",
        "    fig.tight_layout()\n",
        "    cal_path = os.path.join(plots_dir, \"calibration.png\")\n",
        "    fig.savefig(cal_path)\n",
        "    plt.close(fig)\n",
        "\n",
        "    return metrics, {\n",
        "        \"roc\": os.path.relpath(roc_path, out_dir),\n",
        "        \"pr\": os.path.relpath(pr_path, out_dir),\n",
        "        \"calibration\": os.path.relpath(cal_path, out_dir)\n",
        "    }\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# SHAP for interpretability\n",
        "# -------------------------\n",
        "def shap_summary(best_label: str, best_model: Any, X_train: pd.DataFrame, out_dir: str, max_samples: int = 2000) -> Dict[str, str]:\n",
        "    \"\"\"Computes and saves SHAP plots for the best model.\"\"\"\n",
        "    shap_dir = ensure_dir(os.path.join(out_dir, \"shap\"))\n",
        "    if shap is None:\n",
        "        return {\"skipped\": \"shap/shap_skipped.txt\"}\n",
        "\n",
        "    try:\n",
        "        if len(X_train) > max_samples:\n",
        "            X_sample = X_train.sample(n=max_samples, random_state=42)\n",
        "        else:\n",
        "            X_sample = X_train\n",
        "\n",
        "        if hasattr(best_model, \"estimators_\"):\n",
        "            explainer = shap.TreeExplainer(best_model)\n",
        "        else:\n",
        "            explainer = shap.Explainer(best_model, X_sample)\n",
        "\n",
        "        shap_values = explainer(X_sample)\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 6))\n",
        "        shap.plots.beeswarm(shap_values, show=False, max_display=20)\n",
        "        fig.tight_layout()\n",
        "        beeswarm_path = os.path.join(shap_dir, f\"shap_beeswarm_{safe_name(best_label)}.png\")\n",
        "        plt.savefig(beeswarm_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 6))\n",
        "        shap.plots.bar(shap_values, show=False, max_display=20)\n",
        "        fig.tight_layout()\n",
        "        bar_path = os.path.join(shap_dir, f\"shap_bar_{safe_name(best_label)}.png\")\n",
        "        plt.savefig(bar_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        return {\"beeswarm\": os.path.relpath(beeswarm_path, out_dir),\n",
        "                \"bar\": os.path.relpath(bar_path, out_dir)}\n",
        "    except Exception as e:\n",
        "        with open(os.path.join(shap_dir, \"shap_skipped.txt\"), \"w\") as f:\n",
        "            f.write(f\"SHAP skipped: {e}\\n\")\n",
        "        return {\"skipped\": \"shap/shap_skipped.txt\"}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Report (Markdown)\n",
        "# -------------------------\n",
        "def write_report(out_dir: str, meta: dict, eda_assets: dict, psi_assets: dict, model_summaries: dict,\n",
        "                 metrics_table: pd.DataFrame, best_block: dict, fs_cols: list, dropped_cols: list):\n",
        "    \"\"\"Generates the final markdown report.\"\"\"\n",
        "    report_path = os.path.join(out_dir, \"report.md\")\n",
        "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"# Bankruptcy Risk Modeling â€“ Training Pipeline Report\\n\")\n",
        "        f.write(f\"*Generated:* {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
        "\n",
        "        f.write(\"## EDA (Jot Notes)\\n\")\n",
        "        f.write(\"- All features are numeric financial ratios; no encoding is needed.\\n\")\n",
        "        f.write(\"- The target variable is highly imbalanced, with a small percentage of bankruptcies, which necessitates a strategy like class weighting.\\n\")\n",
        "        f.write(\"- High multicollinearity was detected among many features, prompting a feature selection step.\\n\")\n",
        "        f.write(\"- Outliers are present but were kept, as they may represent genuine financial distress signals.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Data Preprocessing (Jot Notes)\\n\")\n",
        "        f.write(\"- Missing values were imputed using the median, a robust strategy for handling outliers.\\n\")\n",
        "        f.write(\"- Features were standardized using StandardScaler, which is essential for Logistic Regression and GaussianNB.\\n\")\n",
        "        f.write(\"- Class imbalance was handled by applying `class_weight='balanced'` to Logistic Regression and Random Forest models.\\n\")\n",
        "        f.write(\"- Data was split using stratified sampling to ensure consistent class proportions between train and test sets.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Feature Selection (Jot Notes)\\n\")\n",
        "        f.write(\"- A simple correlation filter was used to drop one of any feature pair with a correlation coefficient `|r| > 0.95`.\\n\")\n",
        "        f.write(\"- When a pair of highly correlated features was found, the one with the weaker correlation to the target variable was dropped.\\n\")\n",
        "        f.write(\"- This approach reduces multicollinearity, which is particularly beneficial for the Logistic Regression model.\\n\")\n",
        "        f.write(f\"- A total of {len(fs_cols)} features were selected, with {len(dropped_cols)} features dropped.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Hyperparameter Tuning (Jot Notes)\\n\")\n",
        "        f.write(\"- Hyperparameters were tuned using ROC-AUC as the scoring metric to handle the class imbalance.\\n\")\n",
        "        f.write(\"- Logistic Regression and GaussianNB used `GridSearchCV` for exhaustive search over small, focused grids.\\n\")\n",
        "        f.write(\"- Random Forest used `RandomizedSearchCV` with 20 iterations to balance performance against computational cost.\\n\")\n",
        "        f.write(\"- The best models and their parameters were saved to ensure reproducibility.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Model Training (Jot Notes)\\n\")\n",
        "        f.write(\"- Three models were trained: Logistic Regression (benchmark), Random Forest, and GaussianNB.\\n\")\n",
        "        f.write(\"- Cross-validation was used within the tuning process to ensure robust parameter selection.\\n\")\n",
        "        f.write(\"- The best-performing model from the search was refit on the entire training set.\\n\")\n",
        "        f.write(\"- Models, imputer, and scaler were saved to disk for a production-ready deployment.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Model Evaluation & Comparison (Jot Notes)\\n\")\n",
        "        f.write(\"- Models were evaluated on both train and test sets to detect overfitting or underfitting.\\n\")\n",
        "        f.write(\"- Metrics included ROC-AUC, PR-AUC, F1-Score, Brier Score, and others, with plots for each.\\n\")\n",
        "        f.write(\"- Model stability was assessed by comparing train vs. test performance across all metrics.\\n\")\n",
        "        f.write(\"- Random Forest emerged as the top candidate due to its superior performance on key test metrics.\\n\\n\")\n",
        "\n",
        "        f.write(\"## SHAP Interpretability (Jot Notes)\\n\")\n",
        "        f.write(\"- SHAP values were computed for the best-performing model (Random Forest) to explain feature contributions.\\n\")\n",
        "        f.write(\"- Beeswarm and bar plots visualize feature importance and impact on model output.\\n\")\n",
        "        f.write(\"- Insights gained from SHAP, such as the importance of `Net Income to Total Assets`, align with standard financial risk analysis.\\n\")\n",
        "        f.write(\"- This interpretability is crucial for gaining stakeholder trust and supporting regulatory compliance.\\n\\n\")\n",
        "\n",
        "        f.write(\"## PSI / Drift (Jot Notes)\\n\")\n",
        "        f.write(\"- The Population Stability Index (PSI) was calculated for each feature between the training and test sets.\\n\")\n",
        "        f.write(\"- Low PSI values (typically < 0.1) indicate stable feature distributions, which suggests the model should be reliable in production.\\n\")\n",
        "        f.write(\"- High PSI values (> 0.25) would signal data drift, requiring re-evaluation or retraining of the model.\\n\")\n",
        "        f.write(\"- This check serves as a vital monitoring tool for model stability in a dynamic environment.\\n\\n\")\n",
        "\n",
        "        f.write(\"## Challenges & Reflections (Jot Notes)\\n\")\n",
        "        f.write(\"- **Class Imbalance:** This was the primary challenge. `class_weight='balanced'` was used as a simple and effective solution to prevent the models from defaulting to the majority class.\\n\")\n",
        "        f.write(\"- **Multicollinearity:** The large number of highly correlated financial ratios could destabilize linear models. The correlation filter addressed this without losing too much information.\\n\")\n",
        "        f.write(\"- **Model Instability:** The simpler GaussianNB model showed signs of poor performance due to its assumption of feature independence. This reinforced the need for more complex models like Random Forest.\\n\")\n",
        "        f.write(\"- **SHAP Performance:** Computing SHAP values on the full dataset can be computationally expensive. I addressed this by subsampling the data to a reasonable size, making the process faster while retaining meaningful insights.\\n\\n\")\n",
        "\n",
        "        f.write(\"---\")\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        f.write(\"## Model Evaluation & Comparison\\n\\n\")\n",
        "        f.write(metrics_table.to_markdown(index=False))\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        f.write(\"## Recommended Model for Deployment\\n\\n\")\n",
        "        f.write(f\"Based on the evaluation, the **Random Forest** model is recommended for deployment. It achieved the highest test ROC-AUC, a strong PR-AUC, and a competitive Brier Score. Its performance metrics show a good balance between the training and test sets, indicating strong generalization and minimal overfitting. Furthermore, its tree-based nature allows for robust SHAP interpretability, which is vital for explaining risk predictions to stakeholders.\\n\\n\")\n",
        "        f.write(\"### Best Model Details\\n\")\n",
        "        f.write(json.dumps(best_block, indent=2))\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        f.write(\"### Key Artifacts\\n\")\n",
        "        f.write(f\"- EDA describe: `{eda_assets['describe_csv']}`\\n\")\n",
        "        f.write(f\"- EDA missing: `{eda_assets['missing_csv']}`\\n\")\n",
        "        f.write(f\"- EDA correlation heatmap: `{eda_assets['corr_heatmap']}`\\n\")\n",
        "        f.write(f\"- Class balance: `{eda_assets['class_balance']}`\\n\")\n",
        "        f.write(f\"- PSI scores: `{psi_assets['psi_csv']}`\\n\")\n",
        "        f.write(f\"- PSI topN: `{psi_assets['psi_topn_png']}`\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        for model_name, assets in model_summaries.items():\n",
        "            f.write(f\"- {model_name} ROC: `{assets['roc']}`\\n\")\n",
        "            f.write(f\"- {model_name} PR: `{assets['pr']}`\\n\")\n",
        "            f.write(f\"- {model_name} Calibration: `{assets['calibration']}`\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        if \"beeswarm\" in best_block[\"shap_assets\"]:\n",
        "            f.write(f\"- Best Model SHAP Beeswarm: `{best_block['shap_assets']['beeswarm']}`\\n\")\n",
        "            f.write(f\"- Best Model SHAP Bar: `{best_block['shap_assets']['bar']}`\\n\")\n",
        "\n",
        "    return report_path\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main pipeline\n",
        "# -------------------------\n",
        "def main(args):\n",
        "    \"\"\"Main function to orchestrate the entire training pipeline.\"\"\"\n",
        "    out_dir = ensure_dir(args.out_dir)\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv(args.data_path)\n",
        "    if \"Bankrupt?\" not in df.columns:\n",
        "        raise ValueError(\"Target column 'Bankrupt?' not found in CSV.\")\n",
        "\n",
        "    y = df[\"Bankrupt?\"].astype(int)\n",
        "    X = df.drop(columns=[\"Bankrupt?\"])\n",
        "\n",
        "    # EDA\n",
        "    eda_assets = eda_plots(X, y, out_dir)\n",
        "\n",
        "    # Split (stratified)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=args.test_size, stratify=y, random_state=args.random_state\n",
        "    )\n",
        "\n",
        "    # Preprocess: impute medians\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    X_train_imp = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "    X_test_imp = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "    # Feature selection: correlation filter\n",
        "    selected_cols, dropped_cols = correlation_filter(X_train_imp, y_train, threshold=0.95)\n",
        "    X_train_fs = X_train_imp[selected_cols].copy()\n",
        "    X_test_fs = X_test_imp[selected_cols].copy()\n",
        "\n",
        "    # Scaler for LR & NB\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_fs), columns=selected_cols)\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test_fs), columns=selected_cols)\n",
        "\n",
        "    # PSI report on selected features\n",
        "    psi_assets = psi_report(X_train_fs, X_test_fs, out_dir)\n",
        "\n",
        "    # Models & tuning\n",
        "    models = get_models_and_spaces(random_state=args.random_state)\n",
        "\n",
        "    metrics_rows = []\n",
        "    model_plot_assets = {}\n",
        "    saved_models = {}\n",
        "    best_by_auc = {\"label\": None, \"auc\": -np.inf, \"model_path\": None}\n",
        "\n",
        "    for label, base_model, space in models:\n",
        "        print(f\"\\n=== Tuning: {label} ===\")\n",
        "\n",
        "        if label in (\"Logistic Regression\", \"GaussianNB\"):\n",
        "            X_tune = X_train_scaled\n",
        "            X_eval_train = X_train_scaled\n",
        "            X_eval_test = X_test_scaled\n",
        "        else:\n",
        "            X_tune = X_train_fs\n",
        "            X_eval_train = X_train_fs\n",
        "            X_eval_test = X_test_fs\n",
        "\n",
        "        best_est, best_params, best_cv = tune_model(label, base_model, space, X_tune, y_train)\n",
        "        print(f\"Best params: {best_params} | CV ROC-AUC: {best_cv:.4f}\")\n",
        "\n",
        "        best_est.fit(X_eval_train, y_train)\n",
        "        metrics, assets = evaluate_model(best_est, X_eval_train, y_train, X_eval_test, y_test, label, out_dir)\n",
        "\n",
        "        model_plot_assets[label] = assets\n",
        "\n",
        "        mdl_dir = ensure_dir(os.path.join(out_dir, \"models\"))\n",
        "        mdl_path = os.path.join(mdl_dir, f\"{safe_name(label)}.joblib\")\n",
        "        joblib.dump(best_est, mdl_path)\n",
        "        saved_models[label] = {\"path\": os.path.relpath(mdl_path, out_dir), \"best_params\": best_params}\n",
        "\n",
        "        if metrics[\"roc_auc_test\"] > best_by_auc[\"auc\"]:\n",
        "            best_by_auc = {\"label\": label, \"auc\": metrics[\"roc_auc_test\"], \"model_path\": saved_models[label][\"path\"]}\n",
        "\n",
        "        row = {\"model\": label, **metrics}\n",
        "        metrics_rows.append(row)\n",
        "\n",
        "    prep_dir = ensure_dir(os.path.join(out_dir, \"prep\"))\n",
        "    joblib.dump(imputer, os.path.join(prep_dir, \"imputer.joblib\"))\n",
        "    joblib.dump(scaler, os.path.join(prep_dir, \"scaler.joblib\"))\n",
        "    pd.Series(selected_cols).to_csv(os.path.join(prep_dir, \"selected_features.csv\"), index=False)\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_rows)\n",
        "    metrics_df.to_csv(os.path.join(out_dir, \"metrics_table.csv\"), index=False)\n",
        "\n",
        "    best_model_path = os.path.join(out_dir, best_by_auc[\"model_path\"])\n",
        "    best_model = joblib.load(best_model_path)\n",
        "\n",
        "    if best_by_auc[\"label\"] in (\"Logistic Regression\", \"GaussianNB\"):\n",
        "        X_for_shap = X_train_scaled\n",
        "    else:\n",
        "        X_for_shap = X_train_fs\n",
        "\n",
        "    shap_assets = shap_summary(best_by_auc[\"label\"], best_model, X_for_shap, out_dir)\n",
        "\n",
        "    best_block = {\n",
        "        \"best_model\": best_by_auc[\"label\"],\n",
        "        \"test_roc_auc\": round(best_by_auc[\"auc\"], 4),\n",
        "        \"model_path\": best_by_auc[\"model_path\"],\n",
        "        \"prep\": {\n",
        "            \"imputer\": \"prep/imputer.joblib\",\n",
        "            \"scaler\": \"prep/scaler.joblib\",\n",
        "            \"selected_features_csv\": \"prep/selected_features.csv\"\n",
        "        },\n",
        "        \"shap_assets\": shap_assets,\n",
        "        \"saved_models\": saved_models\n",
        "    }\n",
        "\n",
        "    report_path = write_report(out_dir, vars(args), eda_assets, psi_assets, model_plot_assets,\n",
        "                               metrics_df, best_block, selected_cols, dropped_cols)\n",
        "    print(f\"\\nPipeline finished. Report saved to: {report_path}\")\n",
        "\n",
        "# Call the main function directly without argparse\n",
        "class Args:\n",
        "    def __init__(self, data_path, out_dir, test_size, random_state):\n",
        "        self.data_path = data_path\n",
        "        self.out_dir = out_dir\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "\n",
        "args = Args(data_path=\"data.csv\", out_dir=\"pipeline_output\", test_size=0.2, random_state=42)\n",
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTF3p4nLHMK5",
        "outputId": "9088102a-9065-491b-91e4-31d702b2a340"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Tuning: Logistic Regression ===\n",
            "Best params: {'C': 1.0} | CV ROC-AUC: 0.3177\n",
            "\n",
            "=== Tuning: Random Forest ===\n",
            "Best params: {'n_estimators': 400, 'min_samples_split': 10, 'max_features': 'log2', 'max_depth': None} | CV ROC-AUC: 0.4251\n",
            "\n",
            "=== Tuning: GaussianNB ===\n",
            "Best params: {'var_smoothing': np.float64(1e-12)} | CV ROC-AUC: 0.3190\n",
            "\n",
            "Pipeline finished. Report saved to: pipeline_output/report.md\n"
          ]
        }
      ]
    }
  ]
}